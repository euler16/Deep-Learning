{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TS1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/euler16/Deep-Learning/blob/master/TS1.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "cRHkiXnxZXrX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "7fc3f711-0f73-4e09-82e7-d2489c1ec955"
      },
      "cell_type": "code",
      "source": [
        "!pip3 uninstall -y torch; \n",
        "!pip3 install torchvision;\n",
        "!pip3 install matplotlib;"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mSkipping torch as it is not installed.\u001b[0m\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.2.0)\n",
            "Collecting torch (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/43/380514bd9663f1bf708abeb359b8b48d3fabb1c8e95bb3427a980a064c57/torch-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (484.0MB)\n",
            "\u001b[K    64% |████████████████████▋           | 312.0MB 35.0MB/s eta 0:00:05"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 484.0MB 30kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5b55a000 @  0x7f61838551c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-0.4.0\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2018.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.14.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "du68pm7FZ3b0",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "141fdd89-d8ff-4b6f-e083-fe7944ed4793"
      },
      "cell_type": "code",
      "source": [
        "!mkdir quick_draw; !ls quick_draw;\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘quick_draw’: File exists\r\n",
            "/bin/sh: 1: !ls: not found\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d8463ee1-de5c-44a9-a797-640821745276\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d8463ee1-de5c-44a9-a797-640821745276\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ant.npz to ant.npz\n",
            "User uploaded file \"ant.npz\" with length 11269240 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-lxH29t9jdS0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cd ..;\n",
        "import PIL\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import namedtuple\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jxwQmodmqsWb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## DATA PREPROCESSING FUNCTIONS\n",
        "\n",
        "def max_size(data):\n",
        "    \"\"\"larger sequence length in the data set\"\"\"\n",
        "    sizes = [len(seq) for seq in data]\n",
        "    return max(sizes)\n",
        "\n",
        "def purify(strokes):\n",
        "    \"\"\"removes to small or too long sequences + removes large gaps\"\"\"\n",
        "    data = []\n",
        "    for seq in strokes:\n",
        "        if len(seq[:,0]) <= hp.max_seq_length and len(seq[:,0])>10:\n",
        "            seq = np.minimum(seq, 1000)\n",
        "            seq = np.maximum(seq, -1000)\n",
        "            seq = np.array(seq, dtype=np.float32)\n",
        "            data.append(seq)\n",
        "    return data\n",
        "\n",
        "def calculate_normalizing_scale_factor(strokes):\n",
        "    \"\"\"Calculate the normalizing factor explained in appendix of sketch-rnn.\"\"\"\n",
        "    data = []\n",
        "    for i in range(len(strokes)):\n",
        "        for j in range(len(strokes[i])):\n",
        "            data.append(strokes[i][j, 0])\n",
        "            data.append(strokes[i][j, 1])\n",
        "    data = np.array(data)\n",
        "    return np.std(data)\n",
        "\n",
        "def normalize(strokes):\n",
        "    \"\"\"Normalize entire dataset (delta_x, delta_y) by the scaling factor.\"\"\"\n",
        "    data = []\n",
        "    scale_factor = calculate_normalizing_scale_factor(strokes)\n",
        "    for seq in strokes:\n",
        "        seq[:, 0:2] /= scale_factor\n",
        "        data.append(seq)\n",
        "    return data\n",
        "  \n",
        "  \n",
        "def make_batch(batch_size):\n",
        "    batch_idx = np.random.choice(len(data),batch_size)\n",
        "    batch_sequences = [data[idx] for idx in batch_idx]\n",
        "    strokes = []\n",
        "    lengths = []\n",
        "    indice = 0\n",
        "    for seq in batch_sequences:\n",
        "        len_seq = len(seq[:,0])\n",
        "        new_seq = np.zeros((Nmax,5))\n",
        "        new_seq[:len_seq,:2] = seq[:,:2]\n",
        "        new_seq[:len_seq-1,2] = 1-seq[:-1,2]\n",
        "        new_seq[:len_seq,3] = seq[:,2]\n",
        "        new_seq[(len_seq-1):,4] = 1\n",
        "        new_seq[len_seq-1,2:4] = 0\n",
        "        lengths.append(len(seq[:,0]))\n",
        "        strokes.append(new_seq)\n",
        "        indice += 1\n",
        "\n",
        "    if use_cuda:\n",
        "        batch = torch.from_numpy(np.stack(strokes,1)).cuda().float()\n",
        "    else:\n",
        "        batch = torch.from_numpy(np.stack(strokes,1)).float()\n",
        "    return batch, lengths\n",
        "\n",
        "################################ adaptive lr\n",
        "def lr_decay(optimizer):\n",
        "    \"\"\"Decay learning rate by a factor of lr_decay\"\"\"\n",
        "    for param_group in optimizer.param_groups:\n",
        "        if param_group['lr']>hp.min_lr:\n",
        "            param_group['lr'] *= hp.lr_decay\n",
        "    return optimizer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KY3A-Stoh4_U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CPUForgetMult(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CPUForgetMult, self).__init__()\n",
        "\n",
        "    def forward(self, f, x, hidden_init=None):\n",
        "        result = []\n",
        "        forgets = f.split(1, dim=0)\n",
        "        prev_h = hidden_init\n",
        "        for i, h in enumerate((f * x).split(1, dim=0)):\n",
        "            if prev_h is not None: h = h + (1 - forgets[i]) * prev_h\n",
        "            \n",
        "            h = h.view(h.size()[1:])\n",
        "            result.append(h)\n",
        "            prev_h = h\n",
        "        return torch.stack(result)\n",
        "      \n",
        "\n",
        "class ForgetMult(torch.nn.Module):\n",
        "    r\"\"\"ForgetMult computes a simple recurrent equation:\n",
        "    h_t = f_t * x_t + (1 - f_t) * h_{t-1}\n",
        "    This equation is equivalent to dynamic weighted averaging.\n",
        "    Inputs: X, hidden\n",
        "        - X (seq_len, batch, input_size): tensor containing the features of the input sequence.\n",
        "        - F (seq_len, batch, input_size): tensor containing the forget gate values, assumed in range [0, 1].\n",
        "        - hidden_init (batch, input_size): tensor containing the initial hidden state for the recurrence (h_{t-1}).\n",
        "        - use_cuda: If True, use the fast element-wise CUDA kernel for recurrence. If False, uses naive for loop. Default: True.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ForgetMult, self).__init__()\n",
        "\n",
        "    def forward(self, f, x, hidden_init=None, use_cuda=True):\n",
        "        #use_cuda = False\n",
        "        # Avoiding 'RuntimeError: expected a Variable argument, but got NoneType' when hidden_init is None\n",
        "        if hidden_init is None: \n",
        "          return CPUForgetMult()(f, x)\n",
        "        return CPUForgetMult()(f, x, hidden_init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KP6y4GH9-thR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class QRNNLayer(nn.Module):\n",
        "    r\"\"\"Applies a single layer Quasi-Recurrent Neural Network (QRNN) to an input sequence.\n",
        "    Args:\n",
        "        input_size: The number of expected features in the input x.\n",
        "        hidden_size: The number of features in the hidden state h. If not specified, the input size is used.\n",
        "        save_prev_x: Whether to store previous inputs for use in future convolutional windows (i.e. for a continuing sequence such as in language modeling). If true, you must call reset to remove cached previous values of x. Default: False.\n",
        "        window: Defines the size of the convolutional window (how many previous tokens to look when computing the QRNN values). Supports 1 and 2. Default: 1.\n",
        "        zoneout: Whether to apply zoneout (i.e. failing to update elements in the hidden state) to the hidden state updates. Default: 0.\n",
        "        output_gate: If True, performs QRNN-fo (applying an output gate to the output). If False, performs QRNN-f. Default: True.\n",
        "        use_cuda: If True, uses fast custom CUDA kernel. If False, uses naive for loop. Default: True.\n",
        "    Inputs: X, hidden\n",
        "        - X (seq_len, batch, input_size): tensor containing the features of the input sequence.\n",
        "        - hidden (batch, hidden_size): tensor containing the initial hidden state for the QRNN.\n",
        "    Outputs: output, h_n\n",
        "        - output (seq_len, batch, hidden_size): tensor containing the output of the QRNN for each timestep.\n",
        "        - h_n (batch, hidden_size): tensor containing the hidden state for t=seq_len\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size=None, save_prev_x=False, zoneout=0, window=2, output_gate=True, use_cuda=True):\n",
        "        super(QRNNLayer, self).__init__()\n",
        "\n",
        "        #assert window in [1, 2], \"This QRNN implementation currently only handles convolutional window of size 1 or size 2\"\n",
        "        self.window = window\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size if hidden_size else input_size\n",
        "        self.zoneout = zoneout\n",
        "        self.save_prev_x = save_prev_x\n",
        "        self.prevX = None\n",
        "        self.output_gate = output_gate\n",
        "        self.use_cuda = use_cuda\n",
        "\n",
        "        # One large matmul with concat is faster than N small matmuls and no concat\n",
        "        self.linear = nn.Linear(self.window * self.input_size, 3 * self.hidden_size if self.output_gate else 2 * self.hidden_size)\n",
        "\n",
        "    def reset(self):\n",
        "        # If you are saving the previous value of x, you should call this when starting with a new state\n",
        "        self.prevX = None\n",
        "\n",
        "    def forward(self, X, hidden=None):\n",
        "        seq_len, batch_size, _ = X.size()\n",
        "\n",
        "        source = None\n",
        "        if self.window == 1:\n",
        "            source = X\n",
        "        elif self.window == 2:\n",
        "            # Construct the x_{t-1} tensor with optional x_{-1}, otherwise a zeroed out value for x_{-1}\n",
        "            Xm1 = []\n",
        "            Xm1.append(self.prevX if self.prevX is not None else X[:1, :, :] * 0)\n",
        "            # Note: in case of len(X) == 1, X[:-1, :, :] results in slicing of empty tensor == bad\n",
        "            if len(X) > 1:\n",
        "                Xm1.append(X[:-1, :, :])\n",
        "            Xm1 = torch.cat(Xm1, 0)\n",
        "            # Convert two (seq_len, batch_size, hidden) tensors to (seq_len, batch_size, 2 * hidden)\n",
        "            source = torch.cat([X, Xm1], 2)\n",
        "\n",
        "        # Matrix multiplication for the three outputs: Z, F, O\n",
        "        print(type(source))\n",
        "        Y = self.linear(Tensor(source))\n",
        "       \n",
        "        # Convert the tensor back to (batch, seq_len, len([Z, F, O]) * hidden_size)\n",
        "        if self.output_gate:\n",
        "            Y = Y.view(seq_len, batch_size, 3 * self.hidden_size)\n",
        "            Z, F, O = Y.chunk(3, dim=2)\n",
        "        else:\n",
        "            Y = Y.view(seq_len, batch_size, 2 * self.hidden_size)\n",
        "            Z, F = Y.chunk(2, dim=2)\n",
        "        ###\n",
        "        Z = torch.nn.functional.tanh(Z)\n",
        "        F = torch.nn.functional.sigmoid(F)\n",
        "\n",
        "        # If zoneout is specified, we perform dropout on the forget gates in F\n",
        "        # If an element of F is zero, that means the corresponding neuron keeps the old value\n",
        "        if self.zoneout:\n",
        "            if self.training:\n",
        "                mask = F.detach().new(*F.size()).bernoulli_(1 - self.zoneout)\n",
        "                F = F * mask\n",
        "            else:\n",
        "                F *= 1 - self.zoneout\n",
        "\n",
        "        # Ensure the memory is laid out as expected for the CUDA kernel\n",
        "        # This is a null op if the tensor is already contiguous\n",
        "        Z = Z.contiguous()\n",
        "        F = F.contiguous()\n",
        "        # The O gate doesn't need to be contiguous as it isn't used in the CUDA kernel\n",
        "\n",
        "        # Forget Mult\n",
        "        # For testing QRNN without ForgetMult CUDA kernel, C = Z * F may be useful\n",
        "        C = ForgetMult()(F, Z, hidden, use_cuda=self.use_cuda)\n",
        "\n",
        "        # Apply (potentially optional) output gate\n",
        "        if self.output_gate:\n",
        "            H = torch.nn.functional.sigmoid(O) * C\n",
        "        else:\n",
        "            H = C\n",
        "\n",
        "        # In an optimal world we may want to backprop to x_{t-1} but ...\n",
        "        if self.window > 1 and self.save_prev_x:\n",
        "            self.prevX = X[-1:, :, :].detach()\n",
        "\n",
        "        return H, C[-1:, :, :]\n",
        "\n",
        "\n",
        "class QRNN(torch.nn.Module):\n",
        "    r\"\"\"Applies a multiple layer Quasi-Recurrent Neural Network (QRNN) to an input sequence.\n",
        "    Args:\n",
        "        input_size: The number of expected features in the input x.\n",
        "        hidden_size: The number of features in the hidden state h. If not specified, the input size is used.\n",
        "        num_layers: The number of QRNN layers to produce.\n",
        "        layers: List of preconstructed QRNN layers to use for the QRNN module (optional).\n",
        "        save_prev_x: Whether to store previous inputs for use in future convolutional windows (i.e. for a continuing sequence such as in language modeling). If true, you must call reset to remove cached previous values of x. Default: False.\n",
        "        window: Defines the size of the convolutional window (how many previous tokens to look when computing the QRNN values). Supports 1 and 2. Default: 1.\n",
        "        zoneout: Whether to apply zoneout (i.e. failing to update elements in the hidden state) to the hidden state updates. Default: 0.\n",
        "        output_gate: If True, performs QRNN-fo (applying an output gate to the output). If False, performs QRNN-f. Default: True.\n",
        "        use_cuda: If True, uses fast custom CUDA kernel. If False, uses naive for loop. Default: True.\n",
        "    Inputs: X, hidden\n",
        "        - X (seq_len, batch, input_size): tensor containing the features of the input sequence.\n",
        "        - hidden (layers, batch, hidden_size): tensor containing the initial hidden state for the QRNN.\n",
        "    Outputs: output, h_n\n",
        "        - output (seq_len, batch, hidden_size): tensor containing the output of the QRNN for each timestep.\n",
        "        - h_n (layers, batch, hidden_size): tensor containing the hidden state for t=seq_len\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size,\n",
        "                 num_layers=1, bias=True, batch_first=False,\n",
        "                 dropout=0, bidirectional=False, layers=None, **kwargs):\n",
        "        #assert bidirectional == False, 'Bidirectional QRNN is not yet supported'\n",
        "        #assert batch_first == False, 'Batch first mode is not yet supported'\n",
        "        #assert bias == True, 'Removing underlying bias is not yet supported'\n",
        "\n",
        "        super(QRNN, self).__init__()\n",
        "\n",
        "        self.layers = torch.nn.ModuleList(layers if layers else [QRNNLayer(input_size if l == 0 else hidden_size, hidden_size, **kwargs) for l in range(num_layers)])\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = len(layers) if layers else num_layers\n",
        "        self.bias = bias\n",
        "        self.batch_first = batch_first\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "    def reset(self):\n",
        "        r'''If your convolutional window is greater than 1, you must reset at the beginning of each new sequence'''\n",
        "        [layer.reset() for layer in self.layers]\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        next_hidden = []\n",
        "\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            input, hn = layer(input, None if hidden is None else hidden[i])\n",
        "            next_hidden.append(hn)\n",
        "\n",
        "            if self.dropout != 0 and i < len(self.layers) - 1:\n",
        "                input = torch.nn.functional.dropout(input, p=self.dropout, training=self.training, inplace=False)\n",
        "\n",
        "        next_hidden = torch.cat(next_hidden, 0).view(self.num_layers, *next_hidden[0].size()[-2:])\n",
        "\n",
        "        return input, next_hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UZJT2as6EZ2A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        # bidirectional lstm:\n",
        "        self.qrnn = QRNN(5,hp.enc_hidden_size,dropout=hp.dropout)#nn.LSTM(5, hp.enc_hidden_size, \\\n",
        "            #dropout=hp.dropout, bidirectional=True)\n",
        "        # create mu and sigma from lstm's last output:\n",
        "        self.fc_mu = nn.Linear(2*hp.enc_hidden_size, hp.Nz)\n",
        "        self.fc_sigma = nn.Linear(2*hp.enc_hidden_size, hp.Nz)\n",
        "        # active dropout:\n",
        "        self.train()\n",
        "\n",
        "    def forward(self, inputs, batch_size, hidden_cell=None):\n",
        "        if hidden_cell is None:\n",
        "            # then must init with zeros\n",
        "            if use_cuda:\n",
        "                hidden = torch.zeros(2, batch_size, hp.enc_hidden_size).cuda()\n",
        "                #cell = Variable(torch.zeros(2, batch_size, hp.enc_hidden_size).cuda())\n",
        "            else:\n",
        "                hidden = torch.zeros(2, batch_size, hp.enc_hidden_size)\n",
        "                #cell = Variable(torch.zeros(2, batch_size, hp.enc_hidden_size))\n",
        "            hidden_cell = hidden#(hidden, cell)\n",
        "        _, hidden = self.qrnn(inputs.float(), hidden_cell)\n",
        "        # hidden is (2, batch_size, hidden_size), we want (batch_size, 2*hidden_size):\n",
        "        #hidden_forward, hidden_backward = torch.split(hidden,1,0)\n",
        "        #hidden_cat = torch.cat([hidden_forward.squeeze(0), hidden_backward.squeeze(0)],1)\n",
        "        hidden_cat = hidden\n",
        "        # mu and sigma:\n",
        "        mu = self.fc_mu(hidden_cat)\n",
        "        sigma_hat = self.fc_sigma(hidden_cat)\n",
        "        sigma = torch.exp(sigma_hat/2.)\n",
        "        # N ~ N(0,1)\n",
        "        z_size = mu.size()\n",
        "        if use_cuda:\n",
        "            N = torch.normal(torch.zeros(z_size),torch.ones(z_size)).cuda()\n",
        "        else:\n",
        "            N = torch.normal(torch.zeros(z_size),torch.ones(z_size))\n",
        "        z = mu + sigma*N\n",
        "        # mu and sigma_hat are needed for LKL loss\n",
        "        return z, mu, sigma_hat\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        # to init hidden and cell from z:\n",
        "        self.fc_hc = nn.Linear(hp.Nz, 2*hp.dec_hidden_size)\n",
        "        # unidirectional lstm:\n",
        "        self.lstm = nn.LSTM(hp.Nz+5, hp.dec_hidden_size, dropout=hp.dropout)\n",
        "        # create proba distribution parameters from hiddens:\n",
        "        self.fc_params = nn.Linear(hp.dec_hidden_size,6*hp.M+3)\n",
        "\n",
        "    def forward(self, inputs, z, hidden_cell=None):\n",
        "        if hidden_cell is None:\n",
        "            # then we must init from z\n",
        "            hidden,cell = torch.split(F.tanh(self.fc_hc(z)),hp.dec_hidden_size,1)\n",
        "            hidden_cell = (hidden.unsqueeze(0).contiguous(), cell.unsqueeze(0).contiguous())\n",
        "        outputs,(hidden,cell) = self.lstm(inputs, hidden_cell)\n",
        "        # in training we feed the lstm with the whole input in one shot\n",
        "        # and use all outputs contained in 'outputs', while in generate\n",
        "        # mode we just feed with the last generated sample:\n",
        "        if self.training:\n",
        "            y = self.fc_params(outputs.view(-1, hp.dec_hidden_size))\n",
        "        else:\n",
        "            y = self.fc_params(hidden.view(-1, hp.dec_hidden_size))\n",
        "        # separate pen and mixture params:\n",
        "        params = torch.split(y,6,1)\n",
        "        params_mixture = torch.stack(params[:-1]) # trajectory\n",
        "        params_pen = params[-1] # pen up/down\n",
        "        # identify mixture params:\n",
        "        pi,mu_x,mu_y,sigma_x,sigma_y,rho_xy = torch.split(params_mixture,1,2)\n",
        "        # preprocess params::\n",
        "        if self.training:\n",
        "            len_out = Nmax+1\n",
        "        else:\n",
        "            len_out = 1\n",
        "        pi = F.softmax(pi.t().squeeze()).view(len_out,-1,hp.M)\n",
        "        sigma_x = torch.exp(sigma_x.t().squeeze()).view(len_out,-1,hp.M)\n",
        "        sigma_y = torch.exp(sigma_y.t().squeeze()).view(len_out,-1,hp.M)\n",
        "        rho_xy = torch.tanh(rho_xy.t().squeeze()).view(len_out,-1,hp.M)\n",
        "        mu_x = mu_x.t().squeeze().contiguous().view(len_out,-1,hp.M)\n",
        "        mu_y = mu_y.t().squeeze().contiguous().view(len_out,-1,hp.M)\n",
        "        q = F.softmax(params_pen).view(len_out,-1,3)\n",
        "        return pi,mu_x,mu_y,sigma_x,sigma_y,rho_xy,q,hidden,cell\n",
        "\n",
        "class Model():\n",
        "    def __init__(self):\n",
        "        if use_cuda:\n",
        "            self.encoder = EncoderRNN().cuda()\n",
        "            self.decoder = DecoderRNN().cuda()\n",
        "        else:\n",
        "            self.encoder = EncoderRNN()\n",
        "            self.decoder = DecoderRNN()\n",
        "        self.encoder_optimizer = optim.Adam(self.encoder.parameters(), hp.lr)\n",
        "        self.decoder_optimizer = optim.Adam(self.decoder.parameters(), hp.lr)\n",
        "        self.eta_step = hp.eta_min\n",
        "\n",
        "    def make_target(self, batch, lengths):\n",
        "        if use_cuda:\n",
        "            eos = torch.stack([torch.Tensor([0,0,0,0,1])]*batch.size()[1]).cuda().unsqueeze(0)\n",
        "        else:\n",
        "            eos = torch.stack([torch.Tensor([0,0,0,0,1])]*batch.size()[1]).unsqueeze(0)\n",
        "        batch = torch.cat([batch, eos], 0)\n",
        "        mask = torch.zeros(Nmax+1, batch.size()[1])\n",
        "        for indice,length in enumerate(lengths):\n",
        "            mask[:length,indice] = 1\n",
        "        if use_cuda:\n",
        "            mask = Tensor(mask.cuda()).detach()\n",
        "        else:\n",
        "            mask = Tensor(mask).detach()\n",
        "        dx = torch.stack([batch[:,:,0]]*hp.M,2).detach()\n",
        "        dy = torch.stack([batch[:,:,1]]*hp.M,2).detach()\n",
        "        p1 = batch[:,:,2].detach()\n",
        "        p2 = batch[:,:,3].detach()\n",
        "        p3 = batch[:,:,4].detach()\n",
        "        p = torch.stack([p1,p2,p3],2)\n",
        "        return mask,dx,dy,p\n",
        "\n",
        "    def train(self, epoch):\n",
        "        self.encoder.train()\n",
        "        self.decoder.train()\n",
        "        batch, lengths = make_batch(hp.batch_size)\n",
        "        # encode:\n",
        "        z, self.mu, self.sigma = self.encoder(batch, hp.batch_size)\n",
        "        # create start of sequence:\n",
        "        if use_cuda:\n",
        "            sos = torch.stack([torch.Tensor([0,0,1,0,0])]*hp.batch_size).cuda().unsqueeze(0)\n",
        "        else:\n",
        "            sos = torch.stack([torch.Tensor([0,0,1,0,0])]*hp.batch_size).unsqueeze(0)\n",
        "        # had sos at the begining of the batch:\n",
        "        batch_init = torch.cat([sos, batch],0)\n",
        "        # expend z to be ready to concatenate with inputs:\n",
        "        z_stack = torch.stack([z]*(Nmax+1))\n",
        "        # inputs is concatenation of z and batch_inputs\n",
        "        inputs = torch.cat([batch_init, z_stack],2)\n",
        "        # decode:\n",
        "        self.pi, self.mu_x, self.mu_y, self.sigma_x, self.sigma_y, \\\n",
        "            self.rho_xy, self.q, _, _ = self.decoder(inputs, z)\n",
        "        # prepare targets:\n",
        "        mask,dx,dy,p = self.make_target(batch, lengths)\n",
        "        # prepare optimizers:\n",
        "        self.encoder_optimizer.zero_grad()\n",
        "        self.decoder_optimizer.zero_grad()\n",
        "        # update eta for LKL:\n",
        "        self.eta_step = 1-(1-hp.eta_min)*hp.R\n",
        "        # compute losses:\n",
        "        LKL = self.kullback_leibler_loss()\n",
        "        LR = self.reconstruction_loss(mask,dx,dy,p,epoch)\n",
        "        loss = LR + LKL\n",
        "        # gradient step\n",
        "        loss.backward()\n",
        "        # gradient cliping\n",
        "        nn.utils.clip_grad_norm(self.encoder.parameters(), hp.grad_clip)\n",
        "        nn.utils.clip_grad_norm(self.decoder.parameters(), hp.grad_clip)\n",
        "        # optim step\n",
        "        self.encoder_optimizer.step()\n",
        "        self.decoder_optimizer.step()\n",
        "        # some print and save:\n",
        "        if epoch%1==0:\n",
        "            print('epoch',epoch,'loss',loss.data[0],'LR',LR.data[0],'LKL',LKL.data[0])\n",
        "            self.encoder_optimizer = lr_decay(self.encoder_optimizer)\n",
        "            self.decoder_optimizer = lr_decay(self.decoder_optimizer)\n",
        "        if epoch%100==0:\n",
        "            #self.save(epoch)\n",
        "            self.conditional_generation(epoch)\n",
        "\n",
        "    def bivariate_normal_pdf(self, dx, dy):\n",
        "        z_x = ((dx-self.mu_x)/self.sigma_x)**2\n",
        "        z_y = ((dy-self.mu_y)/self.sigma_y)**2\n",
        "        z_xy = (dx-self.mu_x)*(dy-self.mu_y)/(self.sigma_x*self.sigma_y)\n",
        "        z = z_x + z_y -2*self.rho_xy*z_xy\n",
        "        exp = torch.exp(-z/(2*(1-self.rho_xy**2)))\n",
        "        norm = 2*np.pi*self.sigma_x*self.sigma_y*torch.sqrt(1-self.rho_xy**2)\n",
        "        return exp/norm\n",
        "\n",
        "    def reconstruction_loss(self, mask, dx, dy, p, epoch):\n",
        "        pdf = self.bivariate_normal_pdf(dx, dy)\n",
        "        LS = -torch.sum(mask*torch.log(1e-5+torch.sum(self.pi * pdf, 2)))/float(Nmax*hp.batch_size)\n",
        "        LP = -torch.sum(p*torch.log(self.q))/float(Nmax*hp.batch_size)\n",
        "        return LS+LP\n",
        "\n",
        "    def kullback_leibler_loss(self):\n",
        "        LKL = -0.5*torch.sum(1+self.sigma-self.mu**2-torch.exp(self.sigma))\\\n",
        "            /float(hp.Nz*hp.batch_size)\n",
        "        if use_cuda:\n",
        "            KL_min = torch.Tensor([hp.KL_min]).cuda().detach()\n",
        "        else:\n",
        "            KL_min = torch.Tensor([hp.KL_min]).detach()\n",
        "        return hp.wKL*self.eta_step * torch.max(LKL,KL_min)\n",
        "\n",
        "    def save(self, epoch):\n",
        "        sel = np.random.rand()\n",
        "        torch.save(self.encoder.state_dict(), \\\n",
        "            'encoderRNN_sel_%3f_epoch_%d.pth' % (sel,epoch))\n",
        "        torch.save(self.decoder.state_dict(), \\\n",
        "            'decoderRNN_sel_%3f_epoch_%d.pth' % (sel,epoch))\n",
        "\n",
        "    def load(self, encoder_name, decoder_name):\n",
        "        saved_encoder = torch.load(encoder_name)\n",
        "        saved_decoder = torch.load(decoder_name)\n",
        "        self.encoder.load_state_dict(saved_encoder)\n",
        "        self.decoder.load_state_dict(saved_decoder)\n",
        "\n",
        "    def conditional_generation(self, epoch):\n",
        "        batch,lengths = make_batch(1)\n",
        "        # should remove dropouts:\n",
        "        self.encoder.train(False)\n",
        "        self.decoder.train(False)\n",
        "        # encode:\n",
        "        z, _, _ = self.encoder(batch, 1)\n",
        "        if use_cuda:\n",
        "            sos = torch.Tensor([0,0,1,0,0]).view(1,1,-1).cuda()\n",
        "        else:\n",
        "            sos = torch.Tensor([0,0,1,0,0]).view(1,1,-1)\n",
        "        s = sos\n",
        "        seq_x = []\n",
        "        seq_y = []\n",
        "        seq_z = []\n",
        "        hidden_cell = None\n",
        "        for i in range(Nmax):\n",
        "            input = torch.cat([s,z.unsqueeze(0)],2)\n",
        "            # decode:\n",
        "            self.pi, self.mu_x, self.mu_y, self.sigma_x, self.sigma_y, \\\n",
        "                self.rho_xy, self.q, hidden, cell = \\\n",
        "                    self.decoder(input, z, hidden_cell)\n",
        "            hidden_cell = (hidden, cell)\n",
        "            # sample from parameters:\n",
        "            s, dx, dy, pen_down, eos = self.sample_next_state()\n",
        "            #------\n",
        "            seq_x.append(dx)\n",
        "            seq_y.append(dy)\n",
        "            seq_z.append(pen_down)\n",
        "            if eos:\n",
        "                print(i)\n",
        "                break\n",
        "        # visualize result:\n",
        "        x_sample = np.cumsum(seq_x, 0)\n",
        "        y_sample = np.cumsum(seq_y, 0)\n",
        "        z_sample = np.array(seq_z)\n",
        "        sequence = np.stack([x_sample,y_sample,z_sample]).T\n",
        "        make_image(sequence, epoch)\n",
        "\n",
        "    def sample_next_state(self):\n",
        "\n",
        "        def adjust_temp(pi_pdf):\n",
        "            pi_pdf = np.log(pi_pdf)/hp.temperature\n",
        "            pi_pdf -= pi_pdf.max()\n",
        "            pi_pdf = np.exp(pi_pdf)\n",
        "            pi_pdf /= pi_pdf.sum()\n",
        "            return pi_pdf\n",
        "\n",
        "        # get mixture indice:\n",
        "        pi = self.pi[0,0,:].detach().cpu().numpy()\n",
        "        pi = adjust_temp(pi)\n",
        "        pi_idx = np.random.choice(hp.M, p=pi)\n",
        "        # get pen state:\n",
        "        q = self.q[0,0,:].detach().cpu().numpy()\n",
        "        q = adjust_temp(q)\n",
        "        q_idx = np.random.choice(3, p=q)\n",
        "        # get mixture params:\n",
        "        mu_x = self.mu_x[0,0,pi_idx]\n",
        "        mu_y = self.mu_y[0,0,pi_idx]\n",
        "        sigma_x = self.sigma_x[0,0,pi_idx]\n",
        "        sigma_y = self.sigma_y[0,0,pi_idx]\n",
        "        rho_xy = self.rho_xy[0,0,pi_idx]\n",
        "        x,y = sample_bivariate_normal(mu_x,mu_y,sigma_x,sigma_y,rho_xy,greedy=False)\n",
        "        next_state = torch.zeros(5)\n",
        "        next_state[0] = x\n",
        "        next_state[1] = y\n",
        "        next_state[q_idx+2] = 1\n",
        "        if use_cuda:\n",
        "            return Variable(next_state.cuda()).view(1,1,-1),x,y,q_idx==1,q_idx==2\n",
        "        else:\n",
        "            return Variable(next_state).view(1,1,-1),x,y,q_idx==1,q_idx==2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N3Pdj5z8_Vp8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@HyperParameters\n",
        "\n",
        "\n",
        "class HParams():\n",
        "    def __init__(self):\n",
        "        self.data_location = 'ant.npz'\n",
        "        self.enc_hidden_size = 256 #@param {type:\"number\"}\n",
        "        self.dec_hidden_size = 512 #@param {type:\"number\"}\n",
        "        self.Nz = 128\n",
        "        self.M = 20\n",
        "        self.dropout = 0.9 #@param {type:\"slider\",min:0,max:1,step:0.1}\n",
        "        self.batch_size = 100 #@param {type:\"number\"}\n",
        "        self.eta_min = 0.01\n",
        "        self.R = 0.99995\n",
        "        self.KL_min = 0.2\n",
        "        self.wKL = 0.5\n",
        "        self.lr = 0.001\n",
        "        self.lr_decay = 0.9999\n",
        "        self.min_lr = 0.00001\n",
        "        self.grad_clip = 1.\n",
        "        self.temperature = 0.4 #@param {type:\"slider\",min:0,max:1,step:0.1}\n",
        "        self.max_seq_length = 200\n",
        "\n",
        "hp = HParams()\n",
        "dataset = np.load(hp.data_location, encoding='latin1')\n",
        "data = dataset['train']\n",
        "data = purify(data)\n",
        "data = normalize(data)\n",
        "Nmax = max_size(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sSG5BKXWK9ui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1744
        },
        "outputId": "d0c218c7-f1e2-4f4f-fc8f-fc61e3a7d327"
      },
      "cell_type": "code",
      "source": [
        "def sample_bivariate_normal(mu_x,mu_y,sigma_x,sigma_y,rho_xy, greedy=False):\n",
        "    # inputs must be floats\n",
        "    if greedy:\n",
        "      return mu_x,mu_y\n",
        "    mean = [mu_x, mu_y]\n",
        "    sigma_x *= np.sqrt(hp.temperature)\n",
        "    sigma_y *= np.sqrt(hp.temperature)\n",
        "    cov = [[sigma_x * sigma_x, rho_xy * sigma_x * sigma_y],\\\n",
        "        [rho_xy * sigma_x * sigma_y, sigma_y * sigma_y]]\n",
        "    x = np.random.multivariate_normal(mean, cov, 1)\n",
        "    return x[0][0], x[0][1]\n",
        "\n",
        "def make_image(sequence, epoch, name='_output_'):\n",
        "    \"\"\"plot drawing with separated strokes\"\"\"\n",
        "    strokes = np.split(sequence, np.where(sequence[:,2]>0)[0]+1)\n",
        "    fig = plt.figure()\n",
        "    ax1 = fig.add_subplot(111)\n",
        "    for s in strokes:\n",
        "        plt.plot(s[:,0],-s[:,1])\n",
        "    canvas = plt.get_current_fig_manager().canvas\n",
        "    canvas.draw()\n",
        "    pil_image = PIL.Image.frombytes('RGB', canvas.get_width_height(),\n",
        "                 canvas.tostring_rgb())\n",
        "    name = str(epoch)+name+'.jpg'\n",
        "    pil_image.save(name,\"JPEG\")\n",
        "    plt.close(\"all\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    use_cuda = False\n",
        "    model = Model()\n",
        "    for epoch in range(50001):\n",
        "        model.train(epoch)\n",
        "        \n",
        "    model.load('encoder.pth','decoder.pth')\n",
        "    model.conditional_generation(50001)\n",
        "    '''\n",
        "    model.load('encoder.pth','decoder.pth')\n",
        "    model.conditional_generation(0)\n",
        "    #'''"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.FloatTensor'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-e4342eeb281c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encoder.pth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'decoder.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-9aec049adb9a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# encode:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m# create start of sequence:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-9aec049adb9a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, batch_size, hidden_cell)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;31m#cell = Variable(torch.zeros(2, batch_size, hp.enc_hidden_size))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mhidden_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;31m#(hidden, cell)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_cell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m# hidden is (2, batch_size, hidden_size), we want (batch_size, 2*hidden_size):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#hidden_forward, hidden_backward = torch.split(hidden,1,0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-5fd1811305a9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-5fd1811305a9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, hidden)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Matrix multiplication for the three outputs: Z, F, O\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Convert the tensor back to (batch, seq_len, len([Z, F, O]) * hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         See :func:`torch.matmul`.\"\"\"\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(tensor1, tensor2, out)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_contiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: torch.mm received an invalid combination of arguments - got (torch.FloatTensor, Variable), but expected one of:\n * (torch.FloatTensor source, torch.FloatTensor mat2)\n      didn't match because some of the arguments have invalid types: (torch.FloatTensor, !Variable!)\n * (torch.SparseFloatTensor source, torch.FloatTensor mat2)\n      didn't match because some of the arguments have invalid types: (!torch.FloatTensor!, !Variable!)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "OTgURfzeCFKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "b9b4a606-29b3-4eeb-bed8-bd3a1e5afa06"
      },
      "cell_type": "code",
      "source": [
        "layer = torch.nn.Linear(3,2)\n",
        "x = torch.zeros(3,3)\n",
        "print(torch.__version__)\n",
        "y = layer(x)\n",
        "print(type(y))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3.0.post4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-f799c9d909ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: addmm(): argument 'mat1' (position 1) must be Variable, not torch.FloatTensor"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "2XU7RpOYIYps",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}